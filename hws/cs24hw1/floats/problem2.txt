fsum problems

1) Why are the results from
    a. adding in the order that the values appear in the input
    b. adding in increasing order of magnitude
    c. adding in decreasing order of magnitude
different?

The results are different because in C, floats only have 24/23 bits of precision.
So if we add a large float and a small float together, we lose some precision
of the small float, because the significant figures are used up to capture
the value of the large float. That means if we add in increasing order of magnitude,
we will maintain our precision for longer than if we add in decreasing order
of magnitude (and if we add in the order that the values appear in the input,
it just depends on the order of the text input). Note that even when we add in
increasing order of magnitude, we will still lose some precision when we get
to the larger numbers - however, the sum up to that point will be more precise
than the sum at the equivalent point using the decreasing order. So clearly the final
results will deviate for adding in order of increasing/decreasing magnitude.
Then, it is clear to see that adding in the order that the values appear
will also give us a different answer, because the precision maintained along the
way is dependent upon the order in which the input is arranged, which is, in our
case, different than increasing/decreasing order.

2) Of the three approaches that fsum uses, which is the most accurate, and why?

The most accurate approach is approach b: adding in increasing order of magnitude.
The reason why was basically explained in my answer to the above question, but
I'll restate it here. Basically, adding in increasing order will preserve
the precision of the sum for longer than if we add in decreasing order. That is,
by adding the small numbers first, we minimize the loss of precision. If we were
to add the big numbers first, the significant figures would be immediately used
up to capture the value of the large floats, and there would be less room to capture
the significance of the remaining smaller floats. This problem does not occur
when adding in increasing order of magnitude. Since adding in increasing order
of magnitude is the optimal way, we can also conclude that it is better than just
adding the inputs in the order that they are given, which doesn't make any sense
anyways as it depends entirely on how the file was written.

3) What kinds of inputs would also cause the "most accurate" approach to exhibit
large errors?

First let us consider another way to lose precision when adding two floats, a way
in which two floats are added such that the result has too many significant figures
and rounding needs to take place. Consider, for the sake of example, if we only
had two numbers of precision. Now consider what would happen if we added 64 and 50. We get that

  64
+ 50
____
 114

But we only have two numbers of precision. So we have to round 114 to
1.1e2, losing precision in the process. Note that in actuality, we have 24 bits
of precision (and 8 bits to store the exponent). But this example gets the point across.

So, now back to the actual question. We can see that if we have an input file
such that every number uses all 24 bits of precision, all the numbers are of
the same magnitude, and adding the numbers results in a number of greater magnitude,
we will incur the loss of precision discussed right above. That
is, each addition will introduce some error into our answer, basically because
of rounding error. And these errors will not be insignificant because all the numbers
are of the same magnitude, and the error occurs at a significant level (see the
example above, where the error occurs in the ones place).
